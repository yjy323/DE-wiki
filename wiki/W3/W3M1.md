## Docker Image
**A fully functional single-node Hadoop cluster**
- **should automatically start** all necessary Hadoop services
	- [What is best way to start and stop hadoop ecosystem, with command line?](https://stackoverflow.com/questions/17569423/what-is-best-way-to-start-and-stop-hadoop-ecosystem-with-command-line)
	- *start-all.sh*
## HDFS Operations
File와 Directory를 관리하고 데이터 CRUD 작업을 수행하는 명령어와 프로세스
사용자는 HDFS Operations를 통해 분산 파일 시스템의 데이터와 상호작용
### Hadoop CLI
- hdfs dfs
- 파일 시스템
	- -mkdir
	- -put
	- -ls
	- Web UI
		- Port 개방 및 포워딩
## Persistence
HDFS의 데이터를 컨테이너 재시작 또는 종료 이후에도 보존하려면, **Hadoop 데이터 디렉토리**를 Docker의 **호스트 디렉토리와 마운트**하여 **Persistence**를 보장해야 한다.
- Using docker-compose
## Create and Write File in HDFS
- Users should create a directory in HDFS.
	- hdfs dfs -mkdir /path/to/directory
- Users should write a text file into the created directory.
	- hdfs dfs -put /local/path/to/file /hdfs/path/to/directory
- The content of the text file should be verifiable by retrieving it from HDFS.
	- hdfs dfs -cat /hdfs/path/to/file
## Documentation
## Docker Setup
## Hadoop Configuration
## Start Hadoop Services
## Data Operations
## Running Container
## HDFS Operations
## Accessibility
## Submission
