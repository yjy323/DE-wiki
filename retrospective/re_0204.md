## 리뷰

### AWS 강의
- 별도 위키에 작성
### 미션
#### 클러스터 구축
- 개발 및 테스트를 위한 HDFS + YARN 구축 완료
- Hadoop 클러스터 위에 Spark 구축 중 에러 발생
	- Spark가 Hadoop과 어떻게 연결될 수 있나?
		- 먼저 학습하고 이슈를 해결하자
#### W5M1
- RDD 코드 작성 및 Docs를 활용해 내부 동작 이해
	1. pyspark.RDD.aggreagte
		- lambda acc, x : acc + x
		- def **seqOp**(acc, x):
		    for x in partition:
		     acc = acc + x
		    return acc
	2. *API 학습 +*
- RDD 코드를 유의미한 수준까지 어떻게 최적화 할 수 있을지 고민하자
### 프로젝트
#### 분석
1. 신규 모델 출시 상황
2. 해당 모델에 대한 소비자들의 **반응**
	1. 긍/부정
	2. 관심도
		1. 관심도는 다른 지표와 결합되어야 한다.
	3. ... 무슨 반응?
3. **특정 이슈**에 대한 대화
	1. 품질
	2. 가격
	3. A/S
	4. HR
	5. IR
	6. ... etc
4. 우리 Product가 얼마나 금전적 가치가 있을지 수치로 제시할 수 있을까?
#### 브레인스토밍
- 특정 이슈는 무엇이 있을지 많이 던져본다.
	- 품질, 가격, 안전, 정비(A/S), 제조, 디자인, 소프트웨어, UX, 글로벌, 중고차, 모빌리티, ESG
## 회고
### KEEP
- 이전 프로젝트 과정에서 어떻게 아이디어를 떠올렸는지 회고를 읽어보며 리마인드 해봤다. 그 때 고민한 결과들이 cue가 되어 주는 것 같다.
### PROBLEM
- Hadoop 클러스터 구축 중 이슈
	- start-dfs.sh는 개발/테스트 환경에서 사용한다.
	- 운영 환경에서는 오케스트레이션 툴을 사용하는 것이 맞겠다.
	- 나는 운영 환경을 가정하면서 start-dfs.sh 사용한다고 잘못 생각해, 이슈가 서로 맞물리는 문제가 있어서 해결에 어려움을 겪었다.
	- 구축 목표와 프로세스를 명확히 해야겠다.
### TRY
- 우선 이번주 목표를 설정한다. 최대한 Iteration을 짧게 하기 위해 내일 오전 중에는 거북이 알을 많이 낳고, 오후에는 좁히고 구체화해 피드백 받을 수 있도록 한다.
- Spark 클러스터 구축에서는 길을 잃지 않게 학습을 먼저 잘하자.