## 리뷰
### RDD & DAG
#### Executing Spark Jobs
1. Driver 프로그램 시작
	1. SparkContext 생성
	2. RDD Lineage Graph 생성, Transformation의 실행 계획이 메모리에 저장
2. Job 제출(Action)
3. SparkContext의 DAG Scheduler가 Job을 여러 Stage로 나눈다.
	1. Stage는 narrow/wide 기준으로 구분된다.
	2. Stage는 내부에서 다시 병렬로 처리 단위의 Task로 쪼개진다.
4. Task Scheduler
	1. Task를 Executor에 분배한다.
	2. Executor를 실행하기 위한 리소스를 Cluster Manager에 요청한다.
	3. Spark driver는 task 실행에 필요한 프로그램과 의존성을 모두 worker node에 전송한다.
#### Optimize Summary
- Spark의 RDD & DAG는 분산/병렬 환경을 전제로, 그 최적화를 목적으로 한다.
- Task와 Partition 컨셉은 Fault Tolerance와 Parallel process를 쉽게 한다.
	- Partition이 크면 Task가 커지고 분산 처리의 이점이 사라지고, 재실행이 오래 걸린다.
	- Partition이 너무 작으면 Task가 너무 많이 생성돼 스케줄링/리소스 관리 비용, I/O 비용이 커진다.
- RDD는 WORM 컨셉처럼 데이터의 일관성을 신경쓰지 않고 작업을 효율적으로 처리하는데만 집중할 수 있게 한다.
- Lazy Evaluation은 최적화된 DAG를 만들어 Spark가 효율적으로 Job을 실행할 수 있게 한다.
- Spark의 컨셉과 동작을 잘 이해해 최적화된 코드를 작성할 수 있어야 한다.
	- DAG의 Stage가 적을 수록 좋다.
		- Stage의 Boundary가 적다 = Wide Transformation이 적다.
	- Stage의 Task가 적을 수록 좋다.
	- 같은 기능을 처리할 때 RDD를 적게 생성할수록 좋다.
	- Partition 수, 메모리 크기 단위까지 최적화할 수도 있다.
#### 나머지는 WIKI에 정리
### Hadoop cluster on Docker with passwordless SSH communication
- SSH는 Root 권한으로 실행한다.
	- Docker 컨테이너에 SSH를 실행하는건 *일반적으로* 권장되지 않는다.
	- Docker는 VM이 아니고 단일 프로세스 실행을 원칙으로 하기 때문
		- SSH가 단일 프로세스로 동작하는 컨테이너는 아무 의미가 없다.
 - Hadoop는 non-root User로 관리/실행한다.
	 -  root 권한으로 SSH를 실행하고 user를 전환한다.
	 - docker exec를 사용할 때 --user hadoop을 명시한다.
	 - [How do I prevent root access to my docker container](https://stackoverflow.com/questions/57731428/how-do-i-prevent-root-access-to-my-docker-container)
 - [When to use /opt? When to use /usr/local/ instead of /usr/ when creating Debian package](https://stackoverflow.com/questions/56872629/when-to-use-opt-when-to-use-usr-local-instead-of-usr-when-creating-debian)
	 - Hadoop는 의미상 /opt에 설치하는 것이 옳아 보인다.
## 회고
### KEEP
- YARN 기반 Spark와 HDFS를 하나의 클러스터로 짜임새 있게 구축하고 Spark Job을 작성해 실제로 분산 처리되는 과정을 배워보려 했다. 오늘은 클러스터 구축에 어려움을 겪었지만, 미루지 않고 새벽까지 최대한 붙잡고 내일의 작업에 차질이 없도록 열심히 했다.
### PROBLEM
- 시간 관리에 실패했다. 아이젠하워 매트릭스를 사용해 작업의 우선순위는 설정했는데, 가장 우선순위가 높았던 클러스터 구축에서 막혀버리니까 다른 모든 작업이 멈춰버렸다.
	- 특히 하둡 클러스터와 Spark를 아직 연동하지 못해서 내일은 일찍 시작해야 한다.
- 저번 주차에 클러스터 설정을 어느정도 익혔다고 생각했는데, 막상 Interative하게 작성한 커맨드를 Dockerfile에 작성하니 이슈가 많았다.
	- SSH는 root 권한으로 실행하라는데, CLI를 이용할 때는 실행 후, 유저 전환이 자유로워서 어렵지 않았지만 Dockerfile로 옮기니 SSH 실행과 관련한 권한 이슈가 많이 발생했다.
	- Dockerfile을 큼직하게 바꾸는게 아니고, ENV나 명령어를 조금씩 바꾸다보니 나이브하게 '이것만 고치면 되겠지~' 라고 생각해 작업 시간이 훪씬 오래 걸렸다.
	- Dockerfile 작성도 코드처럼 Interactive하게 디버깅하듯 접근하고, 설계를 잘해야한다고 분명 이미 경험했는데, 체화하지 못해서 아쉽다.
### TRY
- RDD와 DAG를 학습하면서 Spark docs를 봤는데 코드를 작성하면서 참고할 내용이 많은 것 같다. 미션을 수행하면서 틈틈히 들여다보자.
	- 동료들이 미션을 해결하는 모습을 옆에서 지켜봤는데 빠르게 배워보자.