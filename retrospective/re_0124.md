## 리뷰
### 프로젝트
#### 아이디어
- 스마트스토어 관련 브레인스토밍에서 시작해 홈쇼핑MD들이 겪는 문제는 없을까?에서 시작
- 홈쇼핑MD는 편성표와 판매하는 상품, 호스트 정보 등 다양한 소스에서 데이터를 수집해야할 것 같았다. 실제로 그런 어려움에 대한 솔직한 글을 보았다.
- 관련 정보 수집 중, 이제는 내 아이디어와 유사하고 더 가치있는 서비스를 만났다.
- 네이버 라이브커머스 영상을 그냥 쳐다보던 중, 실시간 채팅이 꽤 활발해보였고, 개발자 도구를 열어보니 수집할 수 있을 것 같았다. 특히 비슷한 서비스에서는 아직 제공하지 않는 데이터였다. 리뷰 데이터와 같이 새로운 정보를 찾아낼 수 있을 것 같았다.
	- Q. 이 때, 산야님이 데이터를 수집/처리하는 것은 확실히 챌린지가 될 것 같다. 하지만 데이터가 의미없을 수 도 있지 않나? 라는 질문을 주셨다.
	- 이 시점에서 프로토타이핑을 하고 실제로 라이브커머스MD가 실시간 채팅 데이터를 활용하지 못함으로써 문제에 빠질 지 따져 봤어야 한다. 아이디어 도출 단계를 너무 나이브하게 생각해 문제를 구체화하지 못하고 피드백을 요청해 많은 것을 배우지 못했다.
- 그럼에도 팀원과 다른 동료들, 지인들과 소통하며 꽤 흥미로워 보이는 주제를 찾은 것 같아서 그 과정은 즐거웠다. 내일부터 프로토타이핑 하면서 실제로 중요한 문제고 해결까지 할 수 있다면 더 재밌겠다.
#### Prototyping
### Hadoop 학습
대용량 데이터를 분산 환경에서 병렬로 저장·처리하기 위해 만들어진 프레임워크
#### HDFS
**Assumptions/Goals**, 분산 환경에서의 병렬처리로 고가용성을 보장하는 것이 핵심
1. Simple Coherency Model, WORM
2. Moving Computation is Cheaper than Moving Data
3. Portability Across Heterogeneous
---
클라이언트-네임노드-데이터노드 구조
- 파일을 Block 단위로 분산 저장
- Replication을 통한 fault tolerance
**NameNode**
- FS 네임스페이스 관리(파일, 디렉토리 구조, 권한 등)
- 파일을 어떤 블록으로 *분할*할지, 어떤 DataNode에 *배치*할지 결정
	- 네트워크상의 물리적 거리를 고려해 replica 배치
- DataNode의 상태 모니터링
- 메타데이터 관리
**DataNode**
- 실질적으로 *블록 단위 데이터*를 저장
- NameNode에게 자신의 상태를 보고
**Hadoop Client**
1. Hadoop CLI나 API 등을 이용해 HDFS operation을 호출한다.
#### YARN
하나의 *ResourceManager* - App 개수만큼의 *ApplicationMasters*
**ResourceManager**
1. Scheduler: 컨테이너에게 얼마나 많은 리소스를 **할당할지만** 결정하고 스케줄링을 한다.
2. ApplicationMaster: ApplicationMaster의 실행을 요청하고 등록/관리한다.

**NodeManager**
컨테이너의 상태와 리소스 사용량을 모니터링하고 RM에 보고하는 주체로 Agent 프로세스로 동작한다.
ApplicationMaster도 Container의 일종이다.

**ApplicationMaster**
RM과 통신하면서 리소스 컨테이너에 필요한 자원을 요청하고 할당받아 태스크를 실행한다.

**Job Process**
1. 클라이언트의 job 제출
2. ApplicationManager의 AM 등록, 스케줄러에게 보고
	1. AM의 재시작을 관리한다.
3. 스케줄러가 NodeManager에게 컨테이너 할당을 지시
	1. AM의 실패나 재시작은 신경쓰지 않는다.(역할 분리)
4. NodeManager의 AM(컨테이너) 리소스 할당
5. AM의 InputSplit(입력값) 분석, 필요한 task(computation), data blocks 계산
	1. RM에 리소스 요청 - Data Locality 고려 X, 필요한 블록의 위치만을 담아 전달
	2. RM 스케줄러가 **Data Locality를 고려**해 데이터 **블록이 존재하는 위치에 컨테이너를 할당**하려 시도
6. **... 추가 학습 필요**
#### MapReduce
#### Linux User / SSH 학습
- 학습 후 Hadoop 클러스터에 적용 필요

강의 때 듣고 추가로 학습 해야겠다고 생각한 Data Locality를 보장하는 주체를 이해할 수 있었다.
## 회고
### KEEP
- Hadoop 미션을 어느정도 해결하고 다시 개념을 학습하고 정리하는 시간을 가졌다. 나중에 정말 새로운 문제를 만났을 때 생각을 할 수 있으려면 어떤 컨셉, 아키텍처 그리고 어떤 원리를 중심으로 학습해야 할 지 그림이 그려졌다. 한번 시간을 쫙 내서 이론 공부 - 실습하기보단 틈틈히 이론 공부를 하되, 어느정도 경험이 쌓였을 때 다시 집중적으로 공부하는 방법이 좋다고 느껴졌다.
### PROBLEM
- 아이디어 도출 단계를 너무 나이브하게 생각해 문제를 구체화하지 못했다. 지금 돌아보니 브레인스토밍에 살을 붙인 수준이었다.
- 데이터로 증명하지 않고 상상만 붙인 아이디어는 절대 구체적일 수 없다는 것을 느꼈다. 특히 팀원들과 의견만 주고 받다보면 결론 없이 대화가 길어진다. 아이디어를 떠올리고 데이터 기반의 프로토타입으로 증명해야 한다. 그리고 아이디어는 한번 떠올리고, 한번 정해서 끝나는 것이 아니다. 구체화하고 피드백 받고 다시 뒤로 되돌아가 아이디어를 차차 발전 시켜야겠다.
- Team 1의 '누구'의 '문제', 프로토타입을 보니 아이디어가 훨씬 잘 이해됐고 피드백도 구체적으로 받을 수 있음을 깨달았다.
### TRY
- 아이디어의 문제를 구체화하기 위해 다음의 순서로 프로토타입을 구현해본다.
	1. 실제 데이터로 의사결정을 해보고 하나의 구체적인 시나리오를 꾸민다.
	2. 거꾸로 그 의사결정이 중요한 문제인지, 데이터는 문제를 해결하는데 도움이 되는지 증명한다.
	3. 데이터를 수집하거나 처리하는데 실질적인 어려움이 있는지 증명한다.
- 1, 2, 3에 모두 해당한다면 큰 고통을 느끼는 타겟이 존재하고 우리 product가 해결해줄 수 있다.
- 네이버 라이브쇼핑 시나리오
	- 채팅 데이터와 상품 및 방송 관련 데이터를 일부 수집한다.
	- 수집한 데이터를 분석해 다음 방송 기획 목적의 의사결정 시나리오를 꾸민다.
		- 보고서/대시보드 형태의 프로토타입을 만든다.
	- 데이터가 얼마나 가치있었는지 평가한다.
	- 가치 있다면 타겟이 데이터를 수집하고 처리하는데 어려움을 느낄지 평가한다.
- 위 과정을 토/일/월 매일 반복해 피드백 받는 주기를 짧게 한다.
	- 주말 간 다노님께 피드백 받을 수 없을 수 있다. 팀원 간 리뷰와 함께 마케팅 일을 하는 지인에게 피드백을 받아본다.