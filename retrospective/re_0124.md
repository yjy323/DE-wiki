## 리뷰
### 프로젝트
#### 아이디어
#### Prototyping
### Hadoop 학습
대용량 데이터를 분산 환경에서 병렬로 저장·처리하기 위해 만들어진 프레임워크
#### HDFS
**Assumptions/Goals**, 분산 환경에서의 병렬처리로 고가용성을 보장하는 것이 핵심
1. Simple Coherency Model, WORM
2. Moving Computation is Cheaper than Moving Data
3. Portability Across Heterogeneous
---
클라이언트-네임노드-데이터노드 구조
- 파일을 Block 단위로 분산 저장
- Replication을 통한 fault tolerance
**NameNode**
- FS 네임스페이스 관리(파일, 디렉토리 구조, 권한 등)
- 파일을 어떤 블록으로 *분할*할지, 어떤 DataNode에 *배치*할지 결정
	- 네트워크상의 물리적 거리를 고려해 replica 배치
- DataNode의 상태 모니터링
- 메타데이터 관리
**DataNode**
- 실질적으로 *블록 단위 데이터*를 저장
- NameNode에게 자신의 상태를 보고
**Hadoop Client**
1. Hadoop CLI나 API 등을 이용해 HDFS operation을 호출한다.
#### YARN
하나의 *ResourceManager* - App 개수만큼의 *ApplicationMasters*
**ResourceManager**
1. Scheduler: 컨테이너에게 얼마나 많은 리소스를 **할당할지만** 결정하고 스케줄링을 한다.
2. ApplicationMaster: ApplicationMaster의 실행을 요청하고 등록/관리한다.

**NodeManager**
컨테이너의 상태와 리소스 사용량을 모니터링하고 RM에 보고하는 주체로 Agent 프로세스로 동작한다.
ApplicationMaster도 Container의 일종이다.

**ApplicationMaster**
RM과 통신하면서 리소스 컨테이너에 필요한 자원을 요청하고 할당받아 태스크를 실행한다.

**Job Process**
1. 클라이언트의 job 제출
2. ApplicationManager의 AM 등록, 스케줄러에게 보고
	1. AM의 재시작을 관리한다.
3. 스케줄러가 NodeManager에게 컨테이너 할당을 지시
	1. AM의 실패나 재시작은 신경쓰지 않는다.(역할 분리)
4. NodeManager의 AM(컨테이너) 리소스 할당
5. AM의 InputSplit(입력값) 분석, 필요한 task(computation), data blocks 계산
	1. RM에 리소스 요청 - Data Locality 고려 X, 필요한 블록의 위치만을 담아 전달
	2. RM 스케줄러가 **Data Locality를 고려**해 데이터 **블록이 존재하는 위치에 컨테이너를 할당**하려 시도
6. **... 추가 학습 필요**
#### MapReduce
#### Linux User / SSH 학습
- 학습 후 Hadoop 클러스터에 적용 필요

강의 때 듣고 추가로 학습 해야겠다고 생각한 Data Locality를 보장하는 주체를 이해할 수 있었다.
## 회고
### KEEP

### PROBLEM
- 아이디어가 얼마나 구체적이어야 하는 지 오해한 것 같다. 데이터 없이 상상만 시도하면 구체적으로 문제를 정의할 수 없다.
- 아이디어 제시 - 피드백 - **아이디어 확정 OR 폐기** - 프로토타입 작성 단계로 좋은 아이디어를 찾겠다고 착각해 다노님께 피드백을 받고 프로토타입을 작성하겠다고 생각했었다. 그러나 아이디어 + 프로토타입 - 구체화 - 피드백, 그다음 조금 되돌아가 아이디어를 다듬고.. 프로토타입을 작성하는 과정을 반복해 구체화했어야 했다.
- Team 1의 '누구'의 '문제'와 프로토타입을 보고 우리보다 훨씬 좋다는 느낌을 받았다. 프로토타이핑 후 피드백이 크게 도움된다.
### TRY
- 아이디어의 문제를 구체화하기 위해 다음의 순서로 프로토타입을 구현한다.
	1. 실제 데이터로 의사결정하는 구체적인 시나리오를 제시한다.
	2. 거꾸로 그 데이터가 타겟이 의사결정하는데 중요한 정보인지 증명한다.
	3. 타겟이 데이터를 의사결정에 활용할 수 있고, 의미도 있지만 데이터를 구하기 어렵다는 문제를 갖고 있는지 증명한다.
- 1,2,3에 해당한다면 고통을 해결해줄 수 있다.
- 네이버 라이브쇼핑 시나리오
	- 이전 방송의 실시간 채팅 데이터를 수집한다.
	- 데이터를 처리하고 의사결정하는 시나리오를 꾸민다.
	- 의사결정에 얼마나 필요했는지 평가한다.
	- 데이터를 수집하고 처리하기 어려웠는지 평가한다.