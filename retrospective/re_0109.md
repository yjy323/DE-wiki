## 리뷰
### 데일리 스크럼
- 어제 한 일:
  - 주영:
    - ETL 프로세스에 익숙해지는 시간이었음
    - 처음에는 데이터 소스 - ETL - 파일 시스템 - ETL - DB(DW 등)의 과정이라고 이해했지만, 서로 대화를 나누며 E - STG - TL - DB의 과정의 존재와 동작을 이해할 수 있었음
    - 서로 질문을 많이 했다고 생각하늗네, 그 과정에서 질문을 잘하는 법과 잘 이해하는 법을 배웠다.
      - 질문의 주제가 어떤 상황을 다루는지, 어떤 지식이 필요한지 상호 간의 이해 차이(간극)를 줄여야 한다.
      - 그 간극을 줄이기 위해서는 자신이 알고 모르는 것을 인정하고 범위를 좁힐 수 있도록 추가 정보를 던져봐야 한다.
      - ETL 프로세스 자체나 병렬/분산 환경에서 발생할 수 있는 이슈를 잘 몰랐지만 시나리오를 구체화하고 CS 지식을 동원하니 나름의 결론을 도출 할 수 있었다.
    - Logging을 고도화하고 논리적인 기능 단위로 모듈을 리팩토링 했다.
  - 은태님:
    - 도한님이 1/7일 CPU 사용량 모니터링 자료를 보여주셨는데, 이것부터 시작해 MacOS의 멀티 코어 환경에서 GIL이 어떻게 동작하는 지 배울 수 있는 시간이었음
    - 파이썬의 PYTHONPATH 개념을 이해할 수 있었고, 클라우드 환경의 배포에 활용할 수 있을 것 같다고 느낌
  - 도한님:
    - 기존 코드의 수정 없이 ETL 프로세스를 확장할 수 있는 방법을 고민함
    - Extract와 TL 프로세스의 책임을 어떻게 분리할 것인가?에 대한 고민
- 오늘 할 일:
  - 주영:
    - 스스로 ETL 프로세스가 무엇이라고 설명할 수 있도록 지식을 체계적으로 정리한다.
    - 대용량 데이터 및 분산/병렬 환경에서 발생할 수 있는 도전과제에 대해 고민한다.
    - Transform 과정에서 pd.read_json()으로 모두 메모리에 올리는 것은 대용량 데이터를 처리하기 어려운 구조다.
    - Load 과정에서 pd.to_sql()으로 모든 row를 insert 하는 작업은 대용량 데이터를 처리하기 어려운 구조다.
    - 모두 Memory 관련 이슈가 발생할 것 같다. 이것을 해결해본다.
  - 은태님:
    - 갱신되는 과거 자료를 관리하기 위해 Extract한 데이터에 타임스탬프를 추가한다.
    - 타임스탬프를 추가한 이후에도 스크립트의 가용성을 보장하기 위해 코드를 리팩토링한다.
  - 도한님:
    - 코파일럿을 쓰지 않고 Pandas를 다루는 법을 익히고 싶다.
    - pd의 기초를 배우고 싶다.
### 다노님 강의 및 피드백
- **Data Product**
  - Product는 재사용할 수 있어야 하고, **재사용할 가치가 있어야 한다.**
  - Product의 금전적 가치는 변화할 수 있다.
- Product VS Project
  - 데이터를 다루는 문제는 Open-Ended 문제이다.
  - 고객이 원하는 Product를 만들어야 하지만, 고객은 자신이 원하는 것이 무엇인지 모른다.
  - 고객과 엔지니어 사이의 간극을 좁혀야 한다.
    - Data-Driven한 커뮤니케이션을 통해 좁혀야 한다.
    - ad-hoc 분석 같이 Project 수준의 데이터(prototype)를 빠르게 생성하고 빠르게 피드백 받아야 한다.
    - *교육 후반에 프로젝트를 진행할 때, 최대한 데모를 빠르게 많이 만들어 피드백 받을 기회를 높여야겠다.*
- W1M1
  - Q. 이 데이터에 경제적 가치가 있어 보이나?
    - 경제적 가치를 만들기 위해 데이터를 추가해야 할 것이고, 이 작업은 어렵다.
    - 가설 - 데이터 수집 - 검증
- W1M3
  - 핵심 == 시나리오
    - 고객: 경영진
    - 목표: 글로벌 사업성을 평가하기 위한 자동화된 스크립트
    - Q. 사업성이란 무엇이고 어떻게 평가할 수 있는가?
      - A를 통해 구현할 Data Product의 모습을 그릴 수 있다.
  - 고객과 소통하는 일이 가장 중요한 것
  - 요구사항이 불명확하면 **물어봐야 한다**.
- ETL 프로세스를 구분하는 기준
  - **비용**(Computing 자원, 시간, 돈)
    - Extract는 외부 소스와 통신하는 단계로 I/O가 중요하다.
    - Transform은 실제 연산이 많이 발생하기 때문에 메모리와 CPU가 중요하다.
    - 따라서 두 단계는 병목 및 장애가 발생할 지점을 기준으로 구분할 수 있다.
  - 프로세스 단계 별로 다른 성격의 머신을 사용하게 될 것이다.
  - 각 단계의 행위의 목적은 무엇인가? 목적 시스템의 특징과 관련이 있다. 특징은 비용 관점의 문제이다.
- Challenge에 직면해야만 진정 문제를 해결할 수 있다.
- REAME.md에 프로덕트의 사용법이 자세해야 하겠다
### 오늘 한 일
- ETL 프로세스에 대해 학습한 내용을 wiki에 정리한다.
- 다노님의 강의 및 피드백을 통해 배운 내용을 정리한다.
- 과제의 기능 요구사항 중 SQL 쿼리를 개선했다.
- 다노님의 피드백과 병렬/분산 및 대용량 데이터 처리에 대해 고민했던 내용을 내일 반영할 계획이다.
- 웹 스크래핑 방식 대신 IMF API를 활용하도록 리팩토링할 계획이다.

## 회고
### Keep
- 은태님, 도한님과 나누고 나름대로 내린 결론들이 다노님의 설명과 꽤 비슷했다. 귀중한 시간이었다고 생각한다. 강의를 통해 정리되지 않은 개념들을 정확한 표현으로 이해할 수 있었다.
### Problem
- 일단 과제를 완성했다는 생각에 작업이 늘어졌다.
- 어떤 방향으로 성장하려는지, 당장 부족한 것은 무엇인지 다시 돌아보고 목표를 즉각적으로 재설정 해 목표 의식을 가져야겠다.
### Try
- 생각을 한다는게 어떤 의미일까?
- 당장은 커뮤니케이션과 기반 지식과 경험이 중요하다고 느껴지는데 좀 추상적인 것 같다. 나름의 답을 고민해보고 의견을 나눠봐야겠다.