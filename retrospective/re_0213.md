## 리뷰
### 시작 전 계획
- 각자 구현한 Transform 코드 공유
- 코드 merging & 로컬 파이프라인 테스트
- 피드백 받을 프로토타입/아키텍처 정리
- 로컬 파이프라인 AWS 위에 구축
### 프로토타이핑
- 평소에 혼자서 또는 동료들과 나눈 '웹 크롤링 Extract' 단계는 어떤 작업까지 포함하는 걸까? 그 기준이 뭘까? 라는 고민에 대한 다노님의 의견을 들었다. 기술적인 기준이 아니라 생각의 틀을 배웠다.
	- 데이터가 얼마나 정적이거나 동적인가? 데이터는 얼마나 restrict하게 수집되어야 할까?
	- *유즈 케이스와 데이터의 특성*이 기준
- 우리는 가장 간단한 케이스로 간단한 파이프라인을 구축했다.
- 이후 고도화 과정에서는 유즈 케이스를 바탕으로 기준을 세워 코드를 수정하자
- Q. 왜 이 프로덕트를 이런 아키텍처로 구성했나?
	- 근거를 들자
		1. Use case
		2. 비용
			1. 금전적 비용
			2. 인력
			3. 시간
		3. 비즈니스 또는 환경적인 제약 조건
- Feedback
	1. 아이디어 방향성은 OK 그렇지만 구체적인 유즈 케이스 결여
	2. 아이디어를 추상적으로 설명 X, '누구'와 '어떤 문제'가 한눈에 이해되는 사례를 중심으로 스토리텔링 하자
	3. 우리 파이프라인이 생성한 data 중 가장 설득력 있는 사례를 하나 뽑아 데모를 만들어보자.
### 개발
1. Transform
	1. LLM API를 사용하기 때문에 Cleansing 수준의 전처리를 수행한다.
		1. Q. 이게 Spark까지 필요하거나 또는 S3에 저장했다가 다시 메모리로 끌어 올려야 하는 작업인가?
	2. 관심도 지표를 뽑는데 있어 조회수/좋아요 수 등 수치 데이터에 JOIN, GROUP BY, 집계 함수등을 복잡하게 걸어 처리하자. 분명한 Challenge가 있을 것
2. S3 & Redshift
	1. S3와 Redshift의 best practice
		1. 보안
		2. 최적화
			1. 성능
			2. 비용
	2. 그러나 지금은 파이프라인 구축과 운영이 우선이다.
	3. 1차적으로 수집한 데이터를 서비스에 올려 파이프라인을 클라우드 환경에서 테스트한다.
## 회고
### KEEP
- 다른 팀원들과도 아이디어 이야기를 나누고 서로 도울 것이 있다면 질문도 하고 도움도 주는 것이 좋았다. 경쟁 중이기는 하지만 그게 막 느껴지지는 않는다. 다들 힘드니까 서로 힘이 된다.
### PROBLEM
- 지금까지는 의견 교환도 원활하고 작업의 분배도 적절해서 협업이 잘 이루어지고 있다고 느낀다. 그런데 왠지 모를 불안감이 있다. 이번주는 프로토타이핑과 함께 필수 로직만 포함한 파이프라인을 로컬에서 구축하고 AWS에 올리는 것까지가 목표였다. 그래서 고도화 과정에서 마주해야 할 여러 Challenge는 아직 경험하지 못했다.
	- 파이프라인을 빠르게 구축한 이유는 어려운 작업을 앞으로 당기기 위함이었는데, 그 반대의 상황으로 불안감이 느껴진다.
	- 그래도 간단한 파이프라인 기반으로 구체적인 유즈케이스를 이번주 안에 뽑아서 다음주에는 방향을 확실히 잡아 싹 반영하자는 생각을 팀원끼리 공유하고 있다.
### TRY
- 파이프라인 각 단계별로, 그 안에서도 ETL 단계별로라도 유즈 케이스를 조금씩 구체화하자. 그 유즈케이스에서 만날 수 있는 기술적인 챌린지를 미리 미리 정의하자.