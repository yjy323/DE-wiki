## 리뷰
### 주말
#### 금
- S3에 저장된 CSV 파일에 대해 Redshift COPY 명령어 실행 시 스키마 충돌 문제
- AWS Redshift Data API를 이용한 COPY 스크립트 작성
	- COPY 대상 스키마.테이블을 잘못 설정한 실수
#### 토
- S3에서 Redshift로 데이터를 복사하기 위한 S3ToRedshiftOperator를 활용해 DAG Task를 구현한다.
	- 관련 이슈
		1. Redshift가 속한 VPC Public IP 개방 문제
		2. aws_default 설정으로 인한 CLI 호출에 AWS Credentials 자동 추가되는 문제
		3. Redshift Data API 호출에 Secrets Manager 키를 전달할 수 없는 문제
			1. secrets backend 필요
- Redshift + Tableau 연동
	- ODBC 프로그램 설치 및 환경 변수 설정
	- Tableau 연결
#### 일
- 태블로 대시보드 시각화
- 시각화 과정에서 **역으로** Redshift 스키마 설계
	- Q. Filter로 사용할 컬럼은 무엇인가?
	- Q. F/L 전 후를 어떻게 쿼리할 것인가?
	- OLAP는 상향식 설계로 실제 문제에 직면했을 때 대응한다.
	- OLTP는 하향식 설계로 더 엄격하게 모델링한다.
- 고도화 고민
	- 자주 인입되는 분석 목적 쿼리 패턴를 찾아 별도의 테이블(또는 뷰)로 만든다.
	- 우리는 이번 Data Product를 그 패턴으로 설정한다.
	- Redshift, RDB의 성능을 어떤 기준으로 모니터링할 것인가?
		- 메모리/캐시/쿼리 실행 시간 등 성능과 관련한 문제
	- 스키마를 외부에서 주입받아 정합성을 맞출 수 있도록 RDS를 메타 스토어로 사용할 수 있을까?
	- 배치를 돌면서 중복된 데이터/누락된 데이터가 반드시 발생할텐데 데이터 정합성/무결성을 어떻게 보장할까? 
		- 어떤 상황을 구체적으로 그려볼까?
		- 우선 팀원들과 파이프라인을 완성하고 실제로 문제를 겪어보자
		- Data Lake에서 발생하는 중복 VS Data Warehouse에서 발생하는 중복
	- 고도화 포인트를 어떻게 잡을까?
		1. 아이디어('누구'의 '어떤 문제')
		2. 데이터 또는 환경의 특성으로 인해 발생하는 문제
			1. HTTP를 통해야 하는 외부 데이터로 인해 발생하는 문제
			2. Daily 배치로 인해 발생하는 문제
### 강의
- 어렵다.. 다시 학습
### 프로젝트
#### 피드백
- PT는 연극처럼, 각본대로 움직이고 말하자.
	- 아이디어, 프로덕트를 말로 설명하지 말고 스토리 + 시각화(대시보드)로 궁금증을 갖게 하자.
	- 어떻게 구현했는지 자연스럽게 궁금하게 된다.
- 단순히 값을 비교만 하면 의미가 없다.
	- 고통을 겪는 '누구'는 어떤 자료를 보고싶어할까? 자신들이 심혈을 기울인 유니크 세일링 포인트에 대한 고객의 반응이 '지금' 어떤지 보고싶다. 이걸 보여주자.
- Daily VS Monthly 배치
	- Daily도 Stream은 아니기 때문에 전체적인 파이프라인 아키텍처는 비슷하다.
	- 원래 방향인 월 배치 구현 + 모니터링 시스템을 구축하고 일 배치로 고도화하자.
#### Redshift 고도화
- 대시보드에 특화된 MATEREALIZED VIEW 테이블 생성을 위한 3개의 팩트 테이블과 2개의 디멘전 테이블을 설계하고 생성한다.
- 이어서 각 테이블을 채우기 위한 S3ToRedshiftOperator Task를 구현한다.
	- 이 때, COPY 명령어를 사용하면 데이터 중복 또는 누락에 대응하기 어렵다.
		- Redshift는 키 제약 조건을 검증하지 않는다.
		- 해결 방법과 모니터링 방법을 결정해서 구현 이후 바로 적용하자.
## 회고
### KEEP
- 고도화를 시작하면서 데이터를 왜 이렇게 처리해야 할지, 서비스를 왜 사용해야 할지, DB를 왜 이렇게 설계해야 할지 서로 비판적으로 질문하면서 파이프라인을 더 탄탄하게 만들어 간다.
	- 데이터와 처리 환경의 특성을 파악하고 정리하자. 우리 팀에 주어진 시스템 요구사항을 정리하자. 요구사항의 우선 순위대로 파이프라인을 개선한다.
		1. 웹 데이터 특성 상 Ingestion 코드를 수정해야 하는 문제가 필연적으로 발생한다. 모든 경우에 대응할 수 있는 코드라는 개념 자체가 없다. 모니터링으로 해결한다.
		2. 빠르게 수정하고 Retry하지 않으면 데이터를 아예 유실할 수 있다.
		3. 데이터 중복/누락 등 정합성을 앞단에서 보장할 수록 더 좋은 시스템이다.
### PROBLEM
- 
### TRY
- 내일 오전 중 무조건 수집-처리-적재-시각화 파이프라인을 자동화해 실험해야한다. 실험 중 예상치 못한 문제를 만날 수 있고, 시스템 요구사항으로 올려 해결하자.
- Redshift는 상향식으로 설계한다고 한다. 실제로 정해진 비즈니스 요구사항대로 대시보드를 그리는 과정에서 필요한 데이터가 자연스럽게 결정되었다. 이 데이터들을 모아 DW의 여러 테이블을 설계할 수 있었다. 다노님께 받은 피드백대로 대시보드를 개선하면서 변경 사항을 반영하자.