## 리뷰
### 시작 전 계획
1. 각자 프로토타이핑 공유(0.5) ✅
2. 프로토타이핑(1) ✅
3. AWS 공부 - Redshift(1) ✅
4. 데이터 품질을 위한 전처리 계획(0.5) ✅
5. 데이터 품질을 위한 전처리(3) ✅
### 프로토타이핑
1. 추상적인 말로 설명했던 프로토타입을 구체적으로 표현해보자.
	1. 누가 (타겟 세그먼트)
	2. 어디에 (어떤 페이스리프트 포인트에)
	3. 얼만큼 (수치 지표)
	4. 어떤 (긍/부정 또는 단순 관심도)
	5. 반응을 FL 전에 보였었나? FL 후에 보이고 있나?
2. VoC를 사후 모니터링해 이번 페이스 리프트가 효과적이었고, 고객의 반응을 잘 반영했는지 자체 평가하고 향후 계획의 지표로 삼는다.
3. **지표** - 그림으로 표현 ✅
	1. 페이스 리프트의 *효과 정도(상/중/하)*
	2. 페이스 리프트 전/후 전체적인 긍/부정도 관심도 *변화 추이 그래프*
	3. 타겟 세그먼트 별/ 개선 포인트 별 *반응 Table*
		1. 디자인
			1. 요소 1: 페이스리프트 전/후 반응 +20%(긍정)
			2. 요소 2: 페이스리프트 전/후 반응 -10%(부정)
		2. 기능
			1. 요소 1: 페이스리프트 전/후 반응 +10%(긍정)
			2. 요소 2: 페이스리프트 전/후 반응 -15%(부정)
### Redshift
- Redshift 아키텍처 학습
	- DW의 기본 아키텍처와 동일하다.
	- 리더 노드가 쿼리를 받으면 실행 계획을 세우고 컴파일 후 컴퓨팅 노드로 코드를 분배한다.
		- 컴퓨팅 노드는 데이터를 슬라이스 단위로 병렬 처리하는데, 슬라이스는 distributed key 기준으로 파티션된다. 즉, Skewing이 일어나지 않도록 분산 키를 적절히 설정해야 한다.
- Redshift는 어떤 기준과 기술로 최적화할 수 있을까?
	- Serverless로 사용하면 Cluster, Node 수준의 최적화를 관리하지 않아도 된다.
	- 성능 최적화
		1. 좋은 Table 설계
		2. 데이터 Load 방식 설계
		3. 데이터 압축 설계
		4. 쿼리 최적화
	- 지금 단계에서 문서의 모든 내용을 보고 외울 필요는 없다.
	- 어떤 포인트에서 최적화가 일어나는 지 알았으니, 성능 문제가 발생한다면 그 근처에서 발생할 것이다.
	- 모니터링 시스템을 잘 구축해서 실제 문제가 발생했을 때 개선하자.
		- System Views와 CloudWatch의 metrics logs를 보면서 모니터링 해야 한다.
		- 기술적으로는 방법을 알았는데, 각 지표가 어떤 의미인지 파악할 수 있나? ❌
### AWS
1. Spark 최적화를 위해 EMR의 Public IP를 열고 UI에 접근할 수 있도록 세팅 해야한다.
2. OpenAI API를 활용해보고 LLM이 유효하다면 AWS Bedrock의 사용을 우선 자체적으로 검토해보자.
3. Ariflow를 왜 써야할까?
	1. 시스템의 고가용성과 확장성을 고려해야 하니까?
	2. 진짜 보장해야하나?
	3. 우리 서비스의 고가용성이 깨지는 시나리오는 무엇인가? 분석가/디자인팀이 새로운 대시보드를 보지 못하는 것. 이게 긴급하게 Retry를 해야하는 일인가?
		1. EventBridge나 Lambda Trigger로 해결할 수 있나? 이건 일단 ❌
### Transfrom 코드
- 데이터 엔지니어가 NLP를 위한 전처리를 어디까지 처리해야 할까?
	- Tokenize, Stop words, Stemming, Lemmatize는 DS가 함께 붙어서 해야될 것 같다.
	- LLM API를 쓸 때는 오히려 전처리를 과도하게 하면 의미를 잃을 것 같다.
- 문장 분할, 기본적인 Cleansing부터 시작해 다양한 요구사항을 난이도/우선순위 별로 줄 세워보자.
	1. @ 언급, # 해시태그, URL 등 삭제
	2. ??? !!! 등 연속되는 감정 표현 삭제
	3. 불필요한 공백 제거 등
- 로컬에서 Pandas로 구현 - Spark Standalone으로 리팩토링 - Spark Cluster에서 테스트 단계로 구현할 것
## 회고
### KEEP
- 하루 시작 전에 할 일과 목표 시간을 배정해서 작업했더니 진행이 더 잘 된다. 또, 5주 넘게 작업한 일들을 회고로 돌아보면서 '1시간 정도면 어느 정도 일을 처리할 수 있겠다' 라는 나름의 기준이 세워진 것 같다.
- 프로토타입이 조금 추상적이었는데, 그걸 구체적인 말로 정리하고 그림으로 그리면서 팀원들과 생각을 동기화했다. 그러고 나니 막막했던 Transform 과정을 빠르게 쳐낼 수 있었다.
### PROBLEM
- 어떤 작업의 기준을 세우는 일이 참 어렵다. Extract와 Transform을 어디서 나눌 것인가? DE가 해야하는 전처리와 DE+DS가 해야하는 전처리는 어떤 기준인가? 등등
	- 레이어를 엄격하게 나누고 파이프라인의 가용성과 확장성을 강하게 보장하려면 Parsing을 Transform에 포함시킬 것이다. 지금은 Lambda를 남의 돈으로 돌린다고 생각하게 되는데, 내 돈이라면 지금 시스템 구조에서는 Lambda 호출을 줄이려고 하지 않았을까? 그럼 Parsing을 Extract에 포함시킬 것이다. 이렇게 시스템/데이터의 모습에 따라 의사결정이 달라질텐데, 경험이 부족해서인지 그 복잡도가 크게 느껴진다. 어떤 일반적인 해결책에서 시작하고 싶어진다.
### TRY
- 데이터의 품질을 높이기 위한 Transform 요구사항을 막 적어보자.
- Transform 요구사항을 우선순위/난이도 기준으로 정렬하자.
	- 순서대로 구현하면서도 전체 프로세스의 발목을 잡지말자
- 웹 스크래핑 코드도 고도화하자, 지금은 정적으로 요청/파싱만 하는데 전체적으로 시스템을 고도화할 때 반영하자.